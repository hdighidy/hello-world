{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM9X6AsWiXndPlmJ+Fey05a",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hdighidy/hello-world/blob/master/Untitled18.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "XgNwHTxTUW0H"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(z):\n",
        "    \"\"\"\n",
        "    Compute the sigmoid of z\n",
        "\n",
        "    Args:\n",
        "        z (ndarray): A scalar, numpy array of any size.\n",
        "\n",
        "    Returns:\n",
        "        g (ndarray): sigmoid(z), with the same shape as z\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    g = 1/(1+np.exp(-z))\n",
        "\n",
        "    return g"
      ],
      "metadata": {
        "id": "dQckDJqZVMzb"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_cost_logistic(X, y, w, b):\n",
        "    \"\"\"\n",
        "    Computes cost\n",
        "\n",
        "    Args:\n",
        "      X (ndarray (m,n)): Data, m examples with n features\n",
        "      y (ndarray (m,)) : target values\n",
        "      w (ndarray (n,)) : model parameters\n",
        "      b (scalar)       : model parameter\n",
        "\n",
        "    Returns:\n",
        "      cost (scalar): cost\n",
        "    \"\"\"\n",
        "\n",
        "    m = X.shape[0]\n",
        "    cost = 0.0\n",
        "    for i in range(m):\n",
        "        z_i = np.dot(X[i],w) + b\n",
        "        f_wb_i = sigmoid(z_i)\n",
        "        cost +=  -y[i]*np.log(f_wb_i) - (1-y[i])*np.log(1-f_wb_i)\n",
        "\n",
        "    cost = cost / m\n",
        "    return cost\n"
      ],
      "metadata": {
        "id": "IiLglhoJVie1"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_gradient_logistic(X, y, w, b):\n",
        "    \"\"\"\n",
        "    Computes the gradient for logistic regression\n",
        "\n",
        "    Args:\n",
        "      X (ndarray (m,n): Data, m examples with n features\n",
        "      y (ndarray (m,)): target values\n",
        "      w (ndarray (n,)): model parameters\n",
        "      b (scalar)      : model parameter\n",
        "    Returns\n",
        "      dj_dw (ndarray (n,)): The gradient of the cost w.r.t. the parameters w.\n",
        "      dj_db (scalar)      : The gradient of the cost w.r.t. the parameter b.\n",
        "    \"\"\"\n",
        "    m,n = X.shape\n",
        "    dj_dw = np.zeros((n,))                           #(n,)\n",
        "    dj_db = 0.\n",
        "\n",
        "    for i in range(m):\n",
        "        f_wb_i = sigmoid(np.dot(X[i],w) + b)          #(n,)(n,)=scalar\n",
        "        err_i  = f_wb_i  - y[i]                       #scalar\n",
        "        for j in range(n):\n",
        "            dj_dw[j] = dj_dw[j] + err_i * X[i,j]      #scalar\n",
        "        dj_db = dj_db + err_i\n",
        "    dj_dw = dj_dw/m                                   #(n,)\n",
        "    dj_db = dj_db/m                                   #scalar\n",
        "\n",
        "    return dj_db, dj_dw"
      ],
      "metadata": {
        "id": "w6YjuGBcY778"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gradient_descent(X, y, w_in, b_in, alpha, num_iters):\n",
        "    \"\"\"\n",
        "    Performs batch gradient descent\n",
        "\n",
        "    Args:\n",
        "      X (ndarray (m,n)   : Data, m examples with n features\n",
        "      y (ndarray (m,))   : target values\n",
        "      w_in (ndarray (n,)): Initial values of model parameters\n",
        "      b_in (scalar)      : Initial values of model parameter\n",
        "      alpha (float)      : Learning rate\n",
        "      num_iters (scalar) : number of iterations to run gradient descent\n",
        "\n",
        "    Returns:\n",
        "      w (ndarray (n,))   : Updated values of parameters\n",
        "      b (scalar)         : Updated value of parameter\n",
        "    \"\"\"\n",
        "    # An array to store cost J and w's at each iteration primarily for graphing later\n",
        "    J_history = []\n",
        "    w = copy.deepcopy(w_in)  #avoid modifying global w within function\n",
        "    b = b_in\n",
        "\n",
        "    for i in range(num_iters):\n",
        "        # Calculate the gradient and update the parameters\n",
        "        dj_db, dj_dw = compute_gradient_logistic(X, y, w, b)\n",
        "\n",
        "        # Update Parameters using w, b, alpha and gradient\n",
        "        w = w - alpha * dj_dw\n",
        "        b = b - alpha * dj_db\n",
        "\n",
        "        # Save cost J at each iteration\n",
        "        if i<100000:      # prevent resource exhaustion\n",
        "            J_history.append( compute_cost_logistic(X, y, w, b) )\n",
        "\n",
        "        # Print cost every at intervals 10 times or as many iterations if < 10\n",
        "        if i% math.ceil(num_iters / 10) == 0:\n",
        "            print(f\"Iteration {i:4d}: Cost {J_history[-1]}   \")\n",
        "\n",
        "    return w, b, J_history         #return final w,b and J history for graphing\n"
      ],
      "metadata": {
        "id": "oLQEQOXrZA9a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_cost_linear_reg(X, y, w, b, lambda_ = 1):\n",
        "    \"\"\"\n",
        "    Computes the cost over all examples\n",
        "    Args:\n",
        "      X (ndarray (m,n): Data, m examples with n features\n",
        "      y (ndarray (m,)): target values\n",
        "      w (ndarray (n,)): model parameters\n",
        "      b (scalar)      : model parameter\n",
        "      lambda_ (scalar): Controls amount of regularization\n",
        "    Returns:\n",
        "      total_cost (scalar):  cost\n",
        "    \"\"\"\n",
        "\n",
        "    m  = X.shape[0]\n",
        "    n  = len(w)\n",
        "    cost = 0.\n",
        "    for i in range(m):\n",
        "        f_wb_i = np.dot(X[i], w) + b                                   #(n,)(n,)=scalar, see np.dot\n",
        "        cost = cost + (f_wb_i - y[i])**2                               #scalar\n",
        "    cost = cost / (2 * m)                                              #scalar\n",
        "\n",
        "    reg_cost = 0\n",
        "    for j in range(n):\n",
        "        reg_cost += (w[j]**2)                                          #scalar\n",
        "    reg_cost = (lambda_/(2*m)) * reg_cost                              #scalar\n",
        "\n",
        "    total_cost = cost + reg_cost                                       #scalar\n",
        "    return total_cost                                                  #scalar"
      ],
      "metadata": {
        "id": "Bdt0Yf7sc5j_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_cost_logistic_reg(X, y, w, b, lambda_ = 1):\n",
        "    \"\"\"\n",
        "    Computes the cost over all examples\n",
        "    Args:\n",
        "    Args:\n",
        "      X (ndarray (m,n): Data, m examples with n features\n",
        "      y (ndarray (m,)): target values\n",
        "      w (ndarray (n,)): model parameters\n",
        "      b (scalar)      : model parameter\n",
        "      lambda_ (scalar): Controls amount of regularization\n",
        "    Returns:\n",
        "      total_cost (scalar):  cost\n",
        "    \"\"\"\n",
        "\n",
        "    m,n  = X.shape\n",
        "    cost = 0.\n",
        "    for i in range(m):\n",
        "        z_i = np.dot(X[i], w) + b                                      #(n,)(n,)=scalar, see np.dot\n",
        "        f_wb_i = sigmoid(z_i)                                          #scalar\n",
        "        cost +=  -y[i]*np.log(f_wb_i) - (1-y[i])*np.log(1-f_wb_i)      #scalar\n",
        "\n",
        "    cost = cost/m                                                      #scalar\n",
        "\n",
        "    reg_cost = 0\n",
        "    for j in range(n):\n",
        "        reg_cost += (w[j]**2)                                          #scalar\n",
        "    reg_cost = (lambda_/(2*m)) * reg_cost                              #scalar\n",
        "\n",
        "    total_cost = cost + reg_cost                                       #scalar\n",
        "    return total_cost                                                  #scalar"
      ],
      "metadata": {
        "id": "dbsuPua6dGaG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}